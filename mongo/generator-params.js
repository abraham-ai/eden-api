const baseParameters = [
  {
    name: 'width',
    label: 'Width',
    description: 'Width of the creation in pixels',
    default: 768,
    minimum: 256, 
    maximum: 2048,
    step: 64,
  },
  {
    name: 'height',
    label: 'Height',
    description: 'Height of the creation in pixels',
    default: 768,
    minimum: 256, 
    maximum: 2048,
    step: 64,
  },
  {
    name: 'upscale_f',
    label: 'Upscale Factor',
    description: 'Diffusion-based upscaling factor',
    default: 1.5,
    minimum: 1.0,
    maximum: 2.0,
    step: 0.1,
    optional: true,
  },
  {
    name: 'checkpoint',
    label: 'Checkpoint',
    description: 'Which model checkpoint to generate with',
    default: 'eden:eden-v1',
    allowedValues: [
      'eden:eden-v1',
      'gordon-berger:gordon-berger-figurative',
    ],
  },
  {
    name: 'lora',
    label: 'LORA',
    description: '(optional) Use LORA on top of the model. To prompt, use <lora_name> e.g. "A photo of <Bill>". Make sure you load LORA on top of the base model is was trained on!',
    default: '(none)',
    // allowedValues: ['(none)'],
  },
  {
    name: 'lora_scale',
    label: 'LORA scale',
    description: 'How strongly to apply the LoRa weights (0.0 will result in the base model)',
    default: 0.8,
    minimum: 0.0,
    maximum: 1.2,
    step: 0.1,
  },
  {
    name: 'sampler',
    label: 'Sampler',
    description: 'Sampler to use for generation',
    default: 'euler',
    allowedValues: ['euler'],
    //allowedValues: ['klms', 'dpm2', 'dpm2_ancestral', 'heun', 'euler', 'euler_ancestral', 'ddim', 'plms', 'dpm'],
    optional: true,
  },
  {
    name: 'steps',
    label: 'Steps',
    description: 'Number of sampling steps',
    default: 40,
    minimum: 10, 
    maximum: 100,
    optional: true,
  },
  {
    name: 'guidance_scale',
    label: 'Guidance scale',
    description: 'Strength of prompt conditioning guidance',
    default: 7.5,
    minimum: 0.0, 
    maximum: 30.0,
    step: 0.1,
    optional: true,
  },
  {
    name: 'stream',
    label: 'Stream',
    description: 'Yield intermediate results during creation process (if false, only final result is returned)',
    default: true,
    allowedValues: [false, true],
    optional: true,
  },
  {
    name: 'stream_every',
    label: 'Stream every',
    description: 'How often to yield intermediate results (when stream is true). In sampling steps for images, frames for video.',
    default: 1,
    minimum: 1,
    maximum: 10,
    optional: true,
  }
]

const animationParameters = [
  {
    name: 'n_frames',
    label: 'Frames',
    description: 'Number of frames in the video',
    default: 60,
    minimum: 3,
    maximum: 1000,
  },
  {
    name: 'loop',
    label: 'Loop',
    description: 'Loop the output video',
    default: false,
    allowedValues: [false, true],
  },
  {
    name: 'smooth',
    label: 'Smooth',
    description: 'Optimize video for perceptual smoothness between frames (if false, frames are linearly spaced in prompt conditioning space)',
    default: true,
    //allowedValues: [false, true],
    allowedValues: [true],
    optional: true,
  },
  {
    name: 'n_film',
    label: 'FILM Iterations',
    description: 'Optionally apply FILM postprocessing to the generated frames to create a smoother video',
    default: 1,
    allowedValues: [0, 1],
    optional: true,
  },
  {
    name: 'fps',
    label: 'FPS',
    description: 'Frames per second of the output video',
    default: 12,
    minimum: 1,
    maximum: 60,
    optional: true,
  },
  {
    name: 'scale_modulation',
    label: 'Scale Modulation',
    description: 'How much to scale down the guidance scale of the prompt conditioning in between keyframes',
    default: 0.0,
    minimum: 0.0,
    maximum: 0.25,
    step: 0.01,
    optional: true,
  },
]

const createParameters = [
  ...baseParameters,
  {
    name: 'text_input',
    label: 'Prompt',
    description: 'Text prompt for the creation',
    default: null,
    isRequired: true,
  },
  {
    name: 'uc_text',
    label: 'Negative prompt',
    description: 'Unconditional (negative) prompt: what you DONT want to see',
    default: 'watermark, text, nude, naked, nsfw, poorly drawn face, ugly, tiling, out of frame, blurry, blurred, grainy, signature, cut off, draft',
    optional: true,
  },
  {
    name: 'init_image_data',
    label: 'Init image',
    default: null,
    description: 'URL of image to initiate image before diffusion (if null, use random noise)',
    mediaUpload: true,
    optional: true,
  },
  {
    name: 'init_image_strength',
    label: 'Init image strength',
    description: 'How much to weight the initial image in the diffusion process (closer to 1.0 = more influence)',
    default: 0.0,
    minimum: 0.0,
    maximum: 1.0,
    step: 0.01,
    optional: true,
  },
  {
    name: 'n_samples',
    label: 'Samples',
    description: 'Number of samples to create.',
    default: 1,
    allowedValues: [1, 2, 4],
    optional: true,
  },
  {
    name: 'seed',
    label: 'Seed',
    description: 'Set random seed for reproducibility. If blank, will be set randomly.',
    default: null,
    minimum: 0,
    maximum: 1e8,
    optional: true,
  }
]

const interpolationParameters = [
  ...baseParameters,
  ...animationParameters,
  {
    name: 'interpolation_texts',
    label: 'Prompts',
    description: 'Prompts to interpolate through',
    default: [],
    minLength: 2,
    maxLength: 5,
    isRequired: true,
  },
  {
    name: 'interpolation_seeds',
    label: 'Seeds',
    description: 'Random seeds. Must have 1 for each prompt. If left blank, will be set randomly.',
    default: [],
    optional: true,
  }
]

const real2realParameters = [
  ...baseParameters,
  ...animationParameters,
  {
    name: 'interpolation_init_images',
    label: 'Real images',
    description: 'URLs of images to use as init images for real2real',
    default: [],
    mediaUpload: true,
    minLength: 2,
    maxLength: 5,
    isRequired: true,
  },
  {
    name: 'interpolation_init_images_power',
    label: 'Init image power',
    description: 'Power of the init_img_strength curve (how fast init_img_strength declines at the keyframes)',
    default: 3.0,
    minimum: 0.5,
    maximum: 5.0,
    step: 0.01,
    optional: true,
  },
  {
    name: 'interpolation_init_images_min_strength',
    label: 'Init image min strength',
    description: 'Min strength of the init_img during interpolation. Lower values will give the interpolation more freedom, leading to more visual changes at the cost of less smoothness',
    default: 0.25,
    minimum: 0.0,
    maximum: 0.75,
    step: 0.01,
    optional: true,
  },
  {
    name: 'interpolation_init_images_max_strength',
    label: 'Init image max strength',
    description: 'Max strength of the init_img during interpolation. Setting this to 1.0 will exactly reproduce the init imgs at some point in the video, but also causes a slight flicker',
    default: 0.95,
    minimum: 0.5,
    maximum: 1.0,
    step: 0.01,
    optional: true,
  },
  {
    name: 'interpolation_seeds',
    label: 'Interpolation seeds',
    description: 'Random seeds. Must have 1 for each init image. If left blank, will be set randomly.',
    default: [],
    optional: true,
  }
]

const remixParameters = [
  ...baseParameters,
  {
    name: 'init_image_data',
    label: 'Init image',
    description: 'URL of image to initiate image before diffusion (if null, use random noise)',
    default: null,
    mediaUpload: true,
    isRequired: true,
  },
  {
    name: 'init_image_strength',
    label: 'Init image strength',
    description: 'How much to weight the input init image in the diffusion process. Setting this to 0.0 will only use the guessed prompt and no img_guidance',
    default: 0.2,
    minimum: 0.0,
    maximum: 0.8,
    step: 0.01,
  },
  {
    name: 'n_samples',
    label: 'Samples',
    description: 'Number of samples to create remix',
    default: 1,
    allowedValues: [1, 2, 4],
    optional: true,
  },
  {
    name: 'uc_text',
    label: 'Negative prompt',
    description: 'Unconditional (negative) prompt',
    default: 'nude, naked, nsfw, poorly drawn face, ugly, tiling, out of frame, extra limbs, disfigured, deformed body, blurry, blurred, watermark, text, grainy, signature, cut off, draft',
    optional: true,
  },
  {
    name: 'seed',
    label: 'Seed',
    description: 'Set random seed for reproducibility. If blank, will be set randomly.',
    default: null,
    minimum: 0,
    maximum: 1e8,
    optional: true,
  }
]

const interrogateParameters = [
  {
    name: 'init_image_data',
    label: 'Image',
    description: 'URL of image to initiate image before diffusion (if null, use random noise)',
    default: null,
    mediaUpload: true,
    isRequired: true,
  },
]

const loraParameters = [
  {
    name: 'lora_training_urls',
    label: 'Training images',
    description: 'URLs for the image files of target concept to train a LORA for',
    mediaUpload: true,
    default: [],
    minLength: 1,
    maxLength: 8,
    isRequired: true,
  },
  {
    name: 'checkpoint',
    label: 'Base checkpoint',
    description: 'Base checkpoint to train from',
    default: 'eden:eden-v1',
    allowedValues: [
      'eden:eden-v1',
      'gordon-berger:gordon-berger-figurative',
    ],
  },
  {
    name: 'name',
    label: 'LORA name',
    description: 'Choose a name to save the LORA. This also sets how you will trigger the concept when prompting: <lora_name>',
    default: null,
    isRequired: true,
  },
  {
    name: 'use_template',
    label: 'Template',
    description: 'Which template to train from. Person works well, style and object are still experimental.',
    default: 'person',
    allowedValues: ['person', 'object', 'style'],
    isRequired: true,
  },
  {
    name: 'train_text_encoder',
    label: 'Train text encoder',
    description: 'Train a LoRa on top of the text encoder',
    default: true,
    allowedValues: [false, true],
    optional: true,
  },
  {
    name: 'perform_inversion',
    label: 'Perform inversion',
    description: 'Perform textual inversion (find a token to represent your concept)',
    default: true,
    allowedValues: [false, true],
    optional: true,
  },
  {
    name: 'resolution',
    label: 'Resolution',
    description: 'Image resolution (higher res needs lower batch size to avoid OOM!)',
    default: 512,
    minimum: 512,
    maximum: 640,
    optional: true,
  },
  {
    name: 'train_batch_size',
    label: 'Batch size',
    description: 'Training batch size',
    default: 5,
    minimum: 1,
    maximum: 5,
    optional: true,
  },
  {
    name: 'gradient_accumulation_steps',
    label: 'Gradient accumulation steps',
    description: 'Gradient accumulation steps',
    default: 1,
    minimum: 1,
    maximum: 4,
    optional: true,
  },
  {
    name: 'scale_lr',
    label: 'Scale learning rate',
    description: 'Scale learning rate',
    default: true,
    allowedValues: [false, true],
    optional: true,
  },
  {
    name: 'learning_rate_ti',
    label: 'Textual inversion learning rate',
    description: 'Learning rate for textual inversion',
    default: 3e-4,
    minimum: 1e-5,
    maximum: 1e-3,
    step: 1e-5,
    optional: true,
  },
  {
    name: 'continue_inversion',
    label: 'Continue inversion',
    description: 'Continue textual inversion phase while training the LoRa model',
    default: true,
    allowedValues: [false, true],
    optional: true,
  },
  {
    name: 'continue_inversion_lr',
    label: 'Continue inversion learning rate',
    description: 'Continue inversion learning rate (should be relatively low)',
    default: 1e-5,
    minimum: 1e-6,
    maximum: 1e-4,
    step: 1e-6,
    optional: true,
  },
  {
    name: 'learning_rate_unet',
    label: 'U-Net learning rate',
    description: 'Learning rate for U-Net',
    default: 1.5e-5,
    minimum: 1e-6,
    maximum: 1e-4,
    step: 1e-6,
    optional: true,
  },
  {
    name: 'learning_rate_text',
    label: 'Text encoder learning rate',
    description: 'Learning rate for text encoder',
    default: 2.5e-5,
    minimum: 1e-6,
    maximum: 1e-4,
    step: 1e-6,
    optional: true,
  },
  {
    name: 'color_jitter',
    label: 'Color jitter',
    description: 'Color jitter',
    default: true,
    allowedValues: [false, true],
    optional: true,
  },
  {
    name: 'lr_scheduler',
    label: 'LR scheduler',
    description: 'Learning rate scheduler',
    default: 'linear',
    allowedValues: ['linear', 'cosine', 'cosine_with_restarts', 'polynomial', 'constant', 'constant_with_warmup'],
    optional: true,
  },
  {
    name: 'lr_warmup_steps',
    label: 'Warmup steps',
    description: 'Learning rate warmup steps',
    default: 0,
    minimum: 0,
    maximum: 100,
    optional: true,
  },
  // {
  //   name: 'placeholder_tokens',
  //   label: 'Placeholder tokens',
  //   description: 'Placeholder tokens for concept',
  //   default: '<person1>',
  //   optional: true,
  //   isRequired: true,
  // },
  //   {
  //        name: 'use_mask_captioned_data',
  //        label: 'Use mask captioned data',
  //        description: 'Use mask captioned data',
  //        default: false,
  //        //allowedValues: [false, true],
  //        allowedValues: [false],
  //        optional: true,
  //      },
  {
    name: 'max_train_steps_ti',
    label: 'Textual inversion max steps',
    description: 'Max train steps for textual inversion',
    default: 350,
    minimum: 50,
    maximum: 700,
    optional: true,
  },
  {
    name: 'max_train_steps_tuning',
    label: 'Tuning max steps',
    description: 'Max train steps for tuning (U-Net and text encoder)',
    default: 700,
    minimum: 50,
    maximum: 1000,
    optional: true,
  },
  {
    name: 'clip_ti_decay',
    label: 'CLIP textual inversion decay',
    description: 'CLIP textual inversion decay',
    default: true,
    allowedValues: [false, true],
    optional: true,
  },
  {
    name: 'weight_decay_ti',
    label: 'Textual inversion weight decay',
    description: 'Weight decay for textual inversion (regularizes the ti embedding), higher values will look less like the concept, but improve promptability',
    default: 0.0010,
    minimum: 0.0001,
    maximum: 0.005,
    step: 0.0001,
    optional: true,
  },
  {
    name: 'weight_decay_lora',
    label: 'Weight decay',
    description: 'Weight decay for LORA matrices, (regularizes the model), higher values will look less like the concept, but improve promptability',
    default: 0.0015,
    minimum: 0.0001,
    maximum: 0.01,
    step: 0.001,
    optional: true,
  },
  {
    name: 'lora_rank_unet',
    label: 'U-Net rank',
    description: 'LORA rank for U-Net',
    default: 3,
    minimum: 1,
    maximum: 16,
    optional: true,
  },
  {
    name: 'lora_rank_text_encoder',
    label: 'Text encoder rank',
    description: 'LORA rank for text encoder',
    default: 8,
    minimum: 1,
    maximum: 16,
    optional: true,
  },
  {
    name: 'use_extended_lora',
    label: 'Extended LORA',
    description: 'Use extended LORA. (false for faces and objects, true for styles is recommended)',
    default: false,
    allowedValues: [false, true],
    optional: true,
  },
  {
    name: 'use_face_segmentation_condition',
    label: 'Face segmentation',
    description: 'Use face segmentation condition. Disable this when training styles / objects',
    default: true,
    allowedValues: [false, true],
    optional: true,
  }
]

export {
  createParameters,
  interpolationParameters,
  real2realParameters,
  remixParameters,
  interrogateParameters,
  loraParameters,
}